<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <div class="post"> <header class="post-header"> <h1 class="post-title">Demos for "MSFFT"</h1> <p class="post-meta">August 6, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/msfft"> <i class="fa-solid fa-hashtag fa-sm"></i> MSFFT</a>   <a href="/blog/tag/demo"> <i class="fa-solid fa-hashtag fa-sm"></i> demo</a>     ·   <a href="/blog/category/demo-posts"> <i class="fa-solid fa-tag fa-sm"></i> demo-posts</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <ul> <li>Recent advancements in time-domain audio separation networks (TasNets) have markedly propelled the field of speech separation. Unlike conventional time-frequency domain methodologies, TasNets directly model the amalgamated speech signals in the time-domain, employing a convolutional encoder-decoder architecture to effect separation on the output of the encoder. However, the original dual-path framework is characterized by a fixed feature dimension and a constant segment size across all RNN layers, thereby limiting its ability to produce high-resolution features. In this study, we present a novel approach termed Multi-Scale Feature Fusion Transformer Network (MSFFT-Net). The MSFFT-Net incorporates multiple dual-path processing paths in the separation stage, each dedicates to perform feature modeling at different scales. Coarse-grain and fine-grain features are obtained in parallel from different processing paths. In addition, the features from one dual-path processing path can be exchanged and shared with other distinct processing path, ultimately yielding high feature resolution across layers, and thus resulting in more accurate mask estimation. Experimental results on various datasets demonstrate the superiority of the MSFFT-Net over SOTA baselines across diverse datasets in single channel speech separation task.</li> </ul> <h2 id="several-samples-from-wsj0-2mix-dataset">Several samples from WSJ0-2mix DataSet</h2> <table> <thead> <tr> <th style="text-align: center">Mixed Audio</th> <th style="text-align: center">Speaker1</th> <th style="text-align: center">Speaker2</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <h2 id="separation-results-of-our-proposed-msfft-3p-and-msfft-2p">Separation Results of our proposed MSFFT-3P and MSFFT-2P</h2> <table> <thead> <tr> <th style="text-align: center">Mixed Audio</th> <th style="text-align: center">Speaker</th> <th style="text-align: center">Clean</th> <th style="text-align: center">DPRNN</th> <th style="text-align: center">MSFFT-3P</th> <th style="text-align: center">MSFFT-2P</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/441c0211_0.47832_053c0105_-0.47832.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_sepformer.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_sepformer.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/22ga0111_2.1333_050a0507_-2.1333.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_3L.wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/446o030k_0.24698_051c0112_-0.24698.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_3L.wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_2L.wav" controls="" preload=""></audio></td> </tr> </tbody> </table> </div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/brownian-motion.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/brownian-motion.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/brownian-motion.gif-1400.webp"></source> <img src="/assets/img/publication_preview/brownian-motion.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="brownian-motion.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="cll2022" class="col-sm-8"> <div class="title">Multi-Scale Feature Fusion Transformer Network for End-to-End Single Channel Speech Separation (Submitted)</div> <div class="author"> Jian Zhou, Yinhao Xu, Cunhang Fan, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Liang Tao, Zhao Lv, Hon Keung Kwan' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Circuits, Systems, and Signal Processing</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cll2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Jian and Xu, Yinhao and Fan, Cunhang and Tao, Liang and Lv, Zhao and Kwan, Hon Keung}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Scale Feature Fusion Transformer Network for End-to-End Single Channel Speech Separation (Submitted)}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Circuits, Systems, and Signal Processing}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/BCSE-SSAL/">Demo for BCSE-SSAL</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/GMG-ProsodyNet/">Demo for GMG ProsodyNet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/CATAD-for-BCSE/">Demo for CATAD</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/MEDAF/">Introduction for "Controllable Multi-Speaker Emotional Speech Synthesis With Emotion Representation of High Generalization Capability"</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/cmetts/">Introduction for "Controllable Multi-Speaker Emotional Speech Synthesis With Emotion Representation of High Generalization Capability"</a> </li> </div> </body></html>