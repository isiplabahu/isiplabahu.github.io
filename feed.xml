<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://cckio.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://cckio.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-16T03:41:40+00:00</updated><id>https://cckio.github.io/feed.xml</id><title type="html">ISIPLab</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Demo page for “CETTS”</title><link href="https://cckio.github.io/blog/2025/CETTS/" rel="alternate" type="text/html" title="Demo page for “CETTS”"/><published>2025-05-20T00:00:00+00:00</published><updated>2025-05-20T00:00:00+00:00</updated><id>https://cckio.github.io/blog/2025/CETTS</id><content type="html" xml:base="https://cckio.github.io/blog/2025/CETTS/"><![CDATA[<h1 id="controllable-emotional-speech-synthesis-via-emotion-transfer">Controllable Emotional Speech Synthesis via Emotion Transfer</h1> <h2 id="abstract">Abstract</h2> <p>Synthesizing expressive speech based on reference audio style is a key area in emotional speech synthesis. While recent models can produce natural and clear speech, controlling emotional intensity remains a challenge. To address this, we propose a VITS-based TTS model with controllable emotional intensity. We incorporate a pre-trained Emotion2Vec model and design an emotion intensity controller. Emotional embeddings extracted from reference audio via Emo2Vec are fused with phoneme-level text features to enable emotion transfer. We hypothesize—and confirm through experiments—that emotional intensity correlates with pitch and energy. Therefore, we construct the emotional intensity control module around a pitch predictor and an energy predictor to enable global-level control over emotional strength. Experiments show that our model synthesizes speech with quality comparable to ground truth and enables controllable emotional intensity without degrading audio quality.</p> <hr/> <h2 id="1-the-architecture-of-the-proposed-model">1. The Architecture of the Proposed Model</h2> <p><img src="/assets/CETTS/Training.jpg" alt="arch"/></p> <hr/> <h2 id="2-demo-style-transfer-for-emotional-tts">2. Demo: Style Transfer for Emotional TTS</h2> <p>To facilitate fair comparison, we synthesize audios with four emotions using five models.</p> <table> <thead> <tr> <th>Emotion</th> <th>Reference</th> <th>Target Speaker</th> <th>CME-TTS</th> <th>ME-TTS</th> <th>wav2vec2+VITS</th> <th>Ours w/o Intensity Controller</th> <th>Ours</th> </tr> </thead> <tbody> <tr> <td>Happy</td> <td><audio controls="" src="/assets/CETTS/demo1/ref/01010501.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/spk/02071000.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/CME-TTS/happy_s2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ME-TTS/Happy.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/wav2vec+vits/2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/emo2vec+vits/2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ours/2.wav"></audio></td> </tr> <tr> <td>Angry</td> <td><audio controls="" src="/assets/CETTS/demo1/ref/02020500.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/spk/01071000.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/CME-TTS/angry_s1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ME-TTS/Angry.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/wav2vec+vits/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/emo2vec+vits/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ours/1.wav"></audio></td> </tr> <tr> <td>Sad</td> <td><audio controls="" src="/assets/CETTS/demo1/ref/03030500.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/spk/04071000.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/CME-TTS/sad_s4.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ME-TTS/Sad.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/wav2vec+vits/4.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/emo2vec+vits/4.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ours/4.wav"></audio></td> </tr> <tr> <td>Surprise</td> <td><audio controls="" src="/assets/CETTS/demo1/ref/04060500.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/spk/03071000.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/CME-TTS/surprise_s3.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ME-TTS/Surprise.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/wav2vec+vits/3.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/emo2vec+vits/3.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo1/ours/3.wav"></audio></td> </tr> </tbody> </table> <hr/> <h2 id="3-demo-emotion-strength-control-in-emotional-tts">3. Demo: Emotion Strength Control in Emotional TTS</h2> <p>To facilitate fair comparison, we use the same text to synthesize speech in four emotions and three strengths.<br/> Text: <strong>雨后的空气充斥着青草的味道</strong></p> <table> <thead> <tr> <th>Emotion</th> <th>Scale (Low)</th> <th>Ours (Low)</th> <th>Scale (Medium)</th> <th>Ours (Medium)</th> <th>Scale (Strong)</th> <th>Ours (Strong)</th> </tr> </thead> <tbody> <tr> <td>Happy</td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/happy/0.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/happy/0.1/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/happy/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/happy/1.0/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/happy/1.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/happy/3.0/bert_vits_2.wav"></audio></td> </tr> <tr> <td>Angry</td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/angry/0.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/angry/0.1/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/angry/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/angry/1.0/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/angry/1.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/angry/2.0/bert_vits_2.wav"></audio></td> </tr> <tr> <td>Sad</td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/sad/0.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/sad/0.1/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/sad/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/sad/1.0/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/sad/1.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/sad/3.0/bert_vits_2.wav"></audio></td> </tr> <tr> <td>Surprise</td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/surprise/0.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/surprise/0.1/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/surprise/1.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/surprise/1.0/bert_vits_2.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/wav2vec_intensity_demo/surprise/1.5.wav"></audio></td> <td><audio controls="" src="/assets/CETTS/demo2/final_intensity_demo/surprise/3.0/bert_vits_2.wav"></audio></td> </tr> </tbody> </table> <hr/>]]></content><author><name></name></author><category term="demo-posts"/><category term="demo"/><category term="TTS"/><summary type="html"><![CDATA[demo for "Controllable Emotional Speech Synthesis via Emotion Transfer"]]></summary></entry><entry><title type="html">Demo page for “MEDAF”</title><link href="https://cckio.github.io/blog/2025/MEDAF/" rel="alternate" type="text/html" title="Demo page for “MEDAF”"/><published>2025-05-08T00:00:00+00:00</published><updated>2025-05-08T00:00:00+00:00</updated><id>https://cckio.github.io/blog/2025/MEDAF</id><content type="html" xml:base="https://cckio.github.io/blog/2025/MEDAF/"><![CDATA[<p>demo ; code</p> <p>abstract</p> <p>model_arc</p>]]></content><author><name></name></author><category term="demo-posts"/><category term="demo"/><category term="TTS"/><summary type="html"><![CDATA[demo & code]]></summary></entry><entry><title type="html">Demo for BCSE-SSAL</title><link href="https://cckio.github.io/blog/2024/BCSE-SSAL/" rel="alternate" type="text/html" title="Demo for BCSE-SSAL"/><published>2024-12-28T02:38:00+00:00</published><updated>2024-12-28T02:38:00+00:00</updated><id>https://cckio.github.io/blog/2024/BCSE-SSAL</id><content type="html" xml:base="https://cckio.github.io/blog/2024/BCSE-SSAL/"><![CDATA[<h2 id="enhancing-bone-conducted-speech-with-spectrum-similarity-metric-in-adversarial-learning">Enhancing Bone-Conducted Speech with Spectrum Similarity Metric in Adversarial Learning</h2> <ul> <li>Although bone-conducted (BC) speech offers the advantage of being insusceptible to background noise, its transmission path through bone tissue entails not only serious attenuation of high-frequency components but also speech distortion and the loss of unvoiced speech, resulting in a substantial degradation in both speech quality and intelligibility. Existing BC speech enhancement methods focus mainly on approaching high-frequency component restoration but overlook the restoration of missing unvoiced speech and the mitigation of speech distortion, resulting in a noticeable gap in speech quality and intelligibility compared to air-conducted (AC) speech. In this paper, a spectrum-similarity metric based adversarial learning method is proposed for bone-conducted speech enhancement. The acoustic features corresponding to source-excitation and filter-response are disentangled using the WORLD vocoder and mapped to its AC speech counterparts with logarithmic Gaussian normalization and a vocal tract converter, respectively. To reconstruct unvoiced speech from BC speech and decrease the nonlinear speech distortion in BC speech, the vocal tract converter predicts low-dimensional Mel-cepstral coefficients of AC speech using a generator which is supervised by a classification discriminator and a spectrum similarity discriminator. While the classification discriminator is used to distinguish between authentic AC speech and enhanced BC speech, the spectrum similarity discriminator is designed to evaluate the spectrum similarity between enhanced BC speech and its AC counterpart. To evaluate spectrum similarity, the correlation of time-frequency units in spectrum of long duration is captured within the self-attention layer embedded in the spectrum similarity discriminator. Experimental results on various speech datasets show that the proposed method is capable of restoring unvoiced speech segment and diminishing speech distortion, resulting in predicting accurate fine-grained AC spectrum and thus significant improvement in terms of speech quality and speech intelligibility.</li> </ul> <div class="caption"> Ground truth target samples </div> <table> <thead> <tr> <th style="text-align: center">Speakers</th> <th style="text-align: center">BC Speech</th> <th style="text-align: center">AC Speech</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Female</td> <td style="text-align: center"><audio src="/assets/panyan/army/sf_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/tf_1.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">Male</td> <td style="text-align: center"><audio src="/assets/panyan/army/sm_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/tm_1.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">01</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_011404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_011404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">02</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_021404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_021404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">03</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_031404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_031404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">04</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_041404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_041404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">05</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_051404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_051404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">06</td> <td style="text-align: center"><audio src="/assets/panyan/army/s_061404.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/army/t_011404.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Speakers “female” and “male” belong to dataset <a href="https://github.com/echoaimaomao/TM-Speech-Dataset">AEUCHSAC&amp;BC-2017</a> corpus. The paper is available at <a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2019&amp;filename=SXJS201903015&amp;v=d05mCpV2RYLs8ng71bnC33CnjR5MYIoqBZc7RJIfetbtVBAvXWPauy7au%25mmd2FQ5YjXj">here</a>.</p> <p>Speakers “01”、”02”、”03”、”04”、”05”、”06” belong to the paper <a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2019&amp;filename=SXJS201903015&amp;v=d05mCpV2RYLs8ng71bnC33CnjR5MYIoqBZc7RJIfetbtVBAvXWPauy7au%25mmd2FQ5YjXj">here</a>.</p> <div class="caption"> Comparision of proposed method to baseline methods on the TMHINT and AEUCHSAC&amp;BC-2017 dataset. </div> <table> <thead> <tr> <th style="text-align: center">Speakers</th> <th style="text-align: center">GMM</th> <th style="text-align: center">BLSTM</th> <th style="text-align: center">CycleGAN</th> <th style="text-align: center">CycleGAN-VC2</th> <th style="text-align: center">CycleGAN-DAL</th> <th style="text-align: center">Ours</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Female</td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_gmm_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_blstm_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_cyclegan_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_cyclegan-vc2_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_cyclegan-dal_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/f_mdcgan_1.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">Male</td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_gmm_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_blstm_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_cyclegan_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_cyclegan-vc2_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_cyclegan-dal_1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/m_mdcgan_1.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">01</td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/011404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">02</td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/021404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">03</td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/031404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">04</td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/041404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">05</td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/051404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">06</td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_gmm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_blstm.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_cyclegan.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_cyclegan-vc2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_cyclegan-dal.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/tai/061404_mdcgan.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <div class="caption"> Comparison of the proposed method to the Two-stage method on the ESMB BC speech dataset. </div> <table> <thead> <tr> <th style="text-align: center">speakers</th> <th style="text-align: center">AC Speech</th> <th style="text-align: center">BC Speech</th> <th style="text-align: center">The Two-Stage method</th> <th style="text-align: center">Ours</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">01</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/1.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">02</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">03</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/3.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/3.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/3.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/3.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">04</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/4.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/4.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/4.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/4.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">05</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/5.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/5.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/5.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/5.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">06</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/6.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/6.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/6.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/6.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">07</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/17.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/17.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/17.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/17.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">08</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/28.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/28.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/28.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/28.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">09</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/29.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/29.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/29.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/29.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center">10</td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/AC/30.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/BC/30.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/TwoStage/30.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/panyan/ESMB/Ours/30.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="demo-posts"/><category term="BCSE-SSAL"/><category term="demo"/><summary type="html"><![CDATA[Demo for "Enhancing Bone-Conducted Speech with Spectrum Similarity Metric in Adversarial Learning"]]></summary></entry><entry><title type="html">Demos for “MSFFT”</title><link href="https://cckio.github.io/blog/2024/MSFFT/" rel="alternate" type="text/html" title="Demos for “MSFFT”"/><published>2024-08-06T12:12:00+00:00</published><updated>2024-08-06T12:12:00+00:00</updated><id>https://cckio.github.io/blog/2024/MSFFT</id><content type="html" xml:base="https://cckio.github.io/blog/2024/MSFFT/"><![CDATA[<ul> <li>Recent advancements in time-domain audio separation networks (TasNets) have markedly propelled the field of speech separation. Unlike conventional time-frequency domain methodologies, TasNets directly model the amalgamated speech signals in the time-domain, employing a convolutional encoder-decoder architecture to effect separation on the output of the encoder. However, the original dual-path framework is characterized by a fixed feature dimension and a constant segment size across all RNN layers, thereby limiting its ability to produce high-resolution features. In this study, we present a novel approach termed Multi-Scale Feature Fusion Transformer Network (MSFFT-Net). The MSFFT-Net incorporates multiple dual-path processing paths in the separation stage, each dedicates to perform feature modeling at different scales. Coarse-grain and fine-grain features are obtained in parallel from different processing paths. In addition, the features from one dual-path processing path can be exchanged and shared with other distinct processing path, ultimately yielding high feature resolution across layers, and thus resulting in more accurate mask estimation. Experimental results on various datasets demonstrate the superiority of the MSFFT-Net over SOTA baselines across diverse datasets in single channel speech separation task.</li> </ul> <h2 id="several-samples-from-wsj0-2mix-dataset">Several samples from WSJ0-2mix DataSet</h2> <table> <thead> <tr> <th style="text-align: center">Mixed Audio</th> <th style="text-align: center">Speaker1</th> <th style="text-align: center">Speaker2</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/1/22ga010e_0.51468_051c0115_-0.51468_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/2/22ga010l_1.2345_444c020e_-1.2345_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/3/22gc010v_0.76199_050a050i_-0.76199_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/4/050c0105_0.94642_444c020p_-0.94642_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/5/440o030k_1.3697_443o030u_-1.3697_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281_s1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Samples/6/447c020n_1.281_22go0107_-1.281_s2.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <h2 id="separation-results-of-our-proposed-msfft-3p-and-msfft-2p">Separation Results of our proposed MSFFT-3P and MSFFT-2P</h2> <table> <thead> <tr> <th style="text-align: center">Mixed Audio</th> <th style="text-align: center">Speaker</th> <th style="text-align: center">Clean</th> <th style="text-align: center">DPRNN</th> <th style="text-align: center">MSFFT-3P</th> <th style="text-align: center">MSFFT-2P</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/441c0211_0.47832_053c0105_-0.47832.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_sepformer.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_sepformer.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/1/spk2_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/22ga0111_2.1333_050a0507_-2.1333.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_3L.wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/2/spk2_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/446o030k_0.24698_051c0112_-0.24698.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center">spk1</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_3L.wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk1_2L.wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center">spk2</td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_dprnn.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_3L.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/MSFFT/Estimate/3/spk2_2L.wav" controls="" preload=""></audio></td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="demo-posts"/><category term="MSFFT"/><category term="demo"/><summary type="html"><![CDATA[Demos for "Multi-Scale Feature Fusion Transformer Network for End-to-End Single Channel Speech Separation"]]></summary></entry><entry><title type="html">Demo for CATAD</title><link href="https://cckio.github.io/blog/2024/CATAD-for-BCSE/" rel="alternate" type="text/html" title="Demo for CATAD"/><published>2024-08-01T04:11:00+00:00</published><updated>2024-08-01T04:11:00+00:00</updated><id>https://cckio.github.io/blog/2024/CATAD%20for%20BCSE</id><content type="html" xml:base="https://cckio.github.io/blog/2024/CATAD-for-BCSE/"><![CDATA[<h2 id="enhancing-bone-conducted-speech-with-catad-conformer-based-adversarial-training-with-adaptive-diffusion">Enhancing Bone-Conducted Speech with CATAD( Conformer-Based Adversarial Training with Adaptive Diffusion)</h2> <ul> <li>Due to the low-pass filtering effect of human tissues, the high frequency components of bone-conducted (BC) speech suffer severe attenuation, resulting in reduced speech quality and intelligibility. To address this issue, this paper proposes a novel adversarial learning network based on the Conformer architecture and an adaptive diffusion process. In the design of the generator, we deploy a TS-Conformer consisting of two Conformer modules that capture temporal and frequency dependencies, respectively, to enhance the expressiveness of speech features. To ensure the stability of the adversarial learning process and the diversity of the generated results, we adopt an adaptive diffusion process that adds noise to both generated and real data. This challenges the discriminator to distinguish between diffused real data and generated data. Experimental results on the ESMB dataset demonstrate that our proposed method significantly improves BC speech recovery, enhancing both speech quality and intelligibility.</li> </ul> <p><img src="/assets/img/CATAD/Framework.png" alt="model_arc" title="demo"/></p> <table> <thead> <tr> <th>BC Speech</th> <th>AC Speech</th> <th>CATAD(ours)</th> </tr> </thead> <tbody> <tr> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech0_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech0_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech0_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech302_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech302_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech302_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech310_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech310_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech310_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech311_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech311_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech311_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech328_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech328_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> <td><audio src="/assets/CATAD/enhanced_speech/bc_speech328_generated_e2e.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="demo-posts"/><category term="demo"/><summary type="html"><![CDATA[Demo for "CATAD - Conformer-Based Adversarial Training with Adaptive Diffusion for Bone-Conducted Speech Enhancement"]]></summary></entry><entry><title type="html">Demo for GMG ProsodyNet</title><link href="https://cckio.github.io/blog/2024/GMG-ProsodyNet/" rel="alternate" type="text/html" title="Demo for GMG ProsodyNet"/><published>2024-07-09T13:26:00+00:00</published><updated>2024-07-09T13:26:00+00:00</updated><id>https://cckio.github.io/blog/2024/GMG-ProsodyNet</id><content type="html" xml:base="https://cckio.github.io/blog/2024/GMG-ProsodyNet/"><![CDATA[<h2 id="multi-granularity-prosodic-speech-synthesis-with-grammar-information">Multi-granularity Prosodic Speech Synthesis with Grammar Information</h2> <ul> <li>Personalized speech synthesis involves learning an individual’s unique speaking patterns from a reference audio to generate speech that mimics the speaker’s habitual rhythm. However, the one-to-many mapping between text and speech, combined with the dynamic nature of personalized speech style characteristics in the reference audio, poses significant challenges for accurate personalized speech synthesis. <strong>In this paper, we propose a Grammar Infused Multi-granularity Prosody Network (GMG ProsodyNet) for personalized speech synthesis.</strong> Specifically, 1) We model prosodic features hierarchically at the levels of utterance, content syntax, word, and phoneme. We utilize the utterance-level prosodic feature to guide the prediction of fine-grained prosodic features according to the hierarchical property of prosodic features. We introduce a context syntax encoder to improve the prediction accuracy of duration, pitch, and energy characteristics in the synthesized audio. The proposed word-level prosodic encoder can efficiently extract valuable pitch dynamic and speech continuity features from the word spectrum. For controlling subtle prosodic nuances, we employ phoneme-level prosodic modeling. 2) We extract syntax level prosodic features from the syntax graph constructed by Graph Neural Network (GNN) with word as node, exploiting grammatical dependencies between distant words. Experimental results demonstrate that the proposed GMG ProsodyNet can effectively encode delicate and personalized prosodic features, leading to improved speech synthesis quality, fluency, and naturalness.</li> </ul> <h3 id="1-tts-samples-in-the-ablation-study">1. TTS Samples in the Ablation Study</h3> <p>We provide audio samples that are generated by models after gradually removing the context syntax encoder and word level prosodic predictor from GMG ProsodyNet.</p> <h4 id="parallel-prosodic-speech-synthetic">Parallel Prosodic Speech Synthetic</h4> <p>Reference/Target Text: Printing in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/parallel/LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: It is of the first importance that the letter used should be fine in form.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/parallel/LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: That the forms of printed letters should follow more or less closely those of the written character and they followed them very closely.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/parallel/LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: The lower case being in fact invented in the early middle ages.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/parallel/LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: They discarded this for a more completely roman and far less beautiful letter.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/parallel/LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <h4 id="non-parallel-prosodic-speech-synthetic">Non-Parallel Prosodic Speech Synthetic</h4> <p>Target Text: The kitten weighs twenty eight pounds.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">GMG ProsodyNet</th> <th style="text-align: center">GMG ProsodyNet w/o CSynEnc</th> <th style="text-align: center">GMG ProsodyNet w/o CSynencwpre</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/nonparallel/word_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/nonparallel/word_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/nonparallel/word_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/nonparallel/word_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/ablation/nonparallel/word_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <h3 id="2-tts-samples-in-the-comparison-study">2. TTS Samples in the Comparison Study</h3> <p>The following demonstration uses different methods for speech synthesis.</p> <h4 id="parallel-prosodic-speech-synthetic-1">Parallel Prosodic Speech Synthetic</h4> <p>Reference/Target Text: Printing in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">SyntaSpeech</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/FG_LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/syn_LJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0001.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: It is of the first importance that the letter used should be fine in form.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">SyntaSpeech</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/FG_LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/syn_LJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0011.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: That the forms of printed letters should follow more or less closely those of the written character and they followed them very closely.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">SyntaSpeech</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/FG_LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/syn_LJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0017.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: The lower case being in fact invented in the early middle ages.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">SyntaSpeech</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/FG_LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/syn_LJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0020.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <p>Reference/Target Text: They discarded this for a more completely roman and far less beautiful letter.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">SyntaSpeech</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/ada_LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/FG_LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/syn_LJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/parallel/synLJ001-0035.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table> <h4 id="non-parallel-prosodic-speech-synthetic-1">Non-Parallel Prosodic Speech Synthetic</h4> <p>Target Text: The kitten weighs twenty eight pounds.</p> <table> <thead> <tr> <th style="text-align: center">Reference Speech</th> <th style="text-align: center">AdaSpeech</th> <th style="text-align: center">FG-transformerTTS</th> <th style="text-align: center">GMG ProsodyNet</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/FG_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0054.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/FG_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0070.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/FG_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0085.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/FG_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0094.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> <tr> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/ada_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/FG_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> <td style="text-align: center"><audio src="/assets/gmgprosody/comparation/nonparallel/con_LJ001-0111.wav" type="audio/wav" controls="" preload=""></audio></td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="demo-posts"/><category term="GMG"/><category term="ProsodyNet"/><category term="demo"/><summary type="html"><![CDATA[Demo for "Multi-granularity Prosodic Speech Synthesis with Grammar Information"]]></summary></entry><entry><title type="html">Introduction for “Controllable Multi-Speaker Emotional Speech Synthesis With Emotion Representation of High Generalization Capability”</title><link href="https://cckio.github.io/blog/2024/cmetts/" rel="alternate" type="text/html" title="Introduction for “Controllable Multi-Speaker Emotional Speech Synthesis With Emotion Representation of High Generalization Capability”"/><published>2024-06-16T10:33:00+00:00</published><updated>2024-06-16T10:33:00+00:00</updated><id>https://cckio.github.io/blog/2024/cmetts</id><content type="html" xml:base="https://cckio.github.io/blog/2024/cmetts/"><![CDATA[<p><a href="https://woaki.github.io/cmetts/">demo</a> <a href="https://github.com/woaki/tacotron2-cmetts">code</a></p> <p>The aim of multi-speaker emotional speech synthesis is to generate speech for a designated speaker in a desired emotional state. The task is challenging due to the presence of speech variations, such as noise, content, and timbre, which can obstruct emotion extraction and transfer. This paper proposes a new approach to performing multi-speaker emotional speech synthesis. The proposed method, which is based on a seq2seq synthesizer, integrates emotion embedding as a conditioned variable to convey exact emotional information from reference audio to the synthesized speech. To dig emotion representation capability, we utilize a three-dimensional acoustic feature as input. And an emotion generalization module with adaptive instance normalization (AdaIN) is proposed to obtain emotion embedding with high generalization ability, which also results in improved controllability. The derived emotion embedding from the generalization module can be readily conditioned by affine parameters, allowing for control both the emotion category and the emotion intensity of synthesized speech. Various emotional speech synthesis experimental results of the propposed method demonstrate its state-of-the-art performance in multi-speaker emotional speech synthesis, coupled with its advantage of high emotion controllability.</p> <p><img src="/assets/img/cmetts/model_arc_2.png" alt="model_arc" title="demo"/></p>]]></content><author><name></name></author><category term="demo-posts"/><category term="demo"/><category term="TTS"/><summary type="html"><![CDATA[demo & code]]></summary></entry><entry><title type="html">A Title</title><link href="https://cckio.github.io/blog/2023/demo/" rel="alternate" type="text/html" title="A Title"/><published>2023-11-11T03:11:00+00:00</published><updated>2023-11-11T03:11:00+00:00</updated><id>https://cckio.github.io/blog/2023/demo</id><content type="html" xml:base="https://cckio.github.io/blog/2023/demo/"><![CDATA[<h2 id="标题">标题</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 标题
**一个内容**  // 字体加粗
</code></pre></div></div> <p>正文内容</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>包含音频
&lt;audio src="/assets/xxx/xxx.wav" type="audio/wav" controls preload&gt;&lt;/audio&gt;

包含图片
![这是图片](/assets/img/xxx.jpg "demo")

请将所有你的音频、图片放在 /assets 文件夹下，以你的姓名拼音命名的文件夹中
</code></pre></div></div>]]></content><author><name></name></author><category term="demo-posts"/><category term="demo"/><summary type="html"><![CDATA[Demo for "xxxx"]]></summary></entry></feed>