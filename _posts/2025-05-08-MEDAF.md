---
layout: post # 不用改变
title:  Introduction for "Controllable Multi-Speaker Emotional Speech Synthesis With Emotion Representation of High Generalization Capability" # 博客标题
date: 2024-06-16 18:33:00+0800 # 时间
description: demo & code # 博客描述
tags: demo TTS # 标签 -- 以空格分隔
categories: demo-posts # 分类 -- 不需要改变
related_publications: jj2023 # 你的论文
featured: false # 是否在首页展示
thumbnail: # post 预览图, 可以留空, 如有需要请填写 /assets/xxx.jpg
---

demo ; code

Despite rapid advances in the field of emotional text-to-speech
(TTS), previous methods performed the expressive speech
synthesis either with explicit labels or with a fixed-length style embedding extracted from reference speech, both of which can only learn an average style and thus ignores the multi-scale nature of speech prosody.
This paper proposes a multi-scale speech synthesis framework based on DelightfulTTS, which helps enhance the expressiveness of speech.
Specially, we propose a series of key innovations to improve the synthesis performance across different emotional states and speakers.
First, we introduce multi-scale emotion modeling utilizing a dynamic acoustic feature as input. By using the mel-spectrogram, delta, and delta-delta features, the model can effectively capture both global emotional trends and subtle emotional nuances.
Second, we apply style equalization to components at different granularities, effectively mitigating speaker feature leakage while preserving the model’s capacity for expressive emotional representation.
Third, we incorporate a multi-channel conditional adversarial network, which leverages adversarial training to model speech features conditioned on emotional characteristics, thereby enhancing the speech quality and emotion consistency.
Experimental results demonstrate that our method outperforms state-of-the-art approaches in terms of emotional expressiveness, speaker identity preservation, and speech naturalness.

model_arc
